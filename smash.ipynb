{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = [9, 8]\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 74)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "from GPUtil import getGPUs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "try:\n",
    "    NUM_GPU = len(getGPUs())\n",
    "except:\n",
    "    NUM_GPU = 0\n",
    "\n",
    "DATA_DIR = \"data/keras\"\n",
    "BATCH_SIZE = 16 * max(NUM_GPU, 1)\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "IMAGE_ROW_SIZE = 584\n",
    "IMAGE_COLUMN_SIZE = 480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're gonna need these callbacks and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "CHAR_NAMES = os.listdir(os.path.join(DATA_DIR, \"train\", \"images\"))\n",
    "NUM_CHARACTERS = len(CHAR_NAMES)\n",
    "\n",
    "stop_on_val_loss = EarlyStopping(monitor='val_loss', min_delta=0.005, \n",
    "                                 patience=3, verbose=0, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \n",
    "                              patience=2, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, format(matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_model_maybe(model):\n",
    "    if NUM_GPU > 0:\n",
    "        model = multi_gpu_model(model, gpus=NUM_GPU)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def make_generator(folder=\"train\",\n",
    "                   data_gen_args={\"fill_mode\": \"constant\",\n",
    "                                  \"cval\": 0,\n",
    "                                  \"width_shift_range\": 0.05,\n",
    "                                  \"height_shift_range\": 0.05,\n",
    "                                  \"zoom_range\": 0.1,\n",
    "                                  \"horizontal_flip\": True,\n",
    "                                  \"preprocessing_function\": preprocess_input},\n",
    "                   data_flow_args={\"seed\": 1,\n",
    "                                   \"batch_size\": BATCH_SIZE}):\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        directory=os.path.join(DATA_DIR, folder, \"images\"),\n",
    "        target_size=(IMAGE_ROW_SIZE, IMAGE_COLUMN_SIZE),\n",
    "        color_mode='rgb',\n",
    "        **data_flow_args)\n",
    "\n",
    "    return image_generator\n",
    "\n",
    "\n",
    "def count_images(folder=\"train\"):\n",
    "    image_directory = os.path.join(DATA_DIR, folder, \"images\")\n",
    "    data_size = 0\n",
    "\n",
    "    for char_name in os.listdir(image_directory):\n",
    "        char_directory = os.path.join(image_directory, char_name)\n",
    "        data_size += len(os.listdir(char_directory))\n",
    "\n",
    "    return data_size\n",
    "\n",
    "\n",
    "def steps_per_epoch(folder=\"train\", batch_size=BATCH_SIZE):\n",
    "    return count_images(folder) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features from my Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just fyi, in the following we're only dealing with about 30% of all the images.  That's to ensure we can fit all the cached features in memory.  We generated these lists with `make keras KERAS_TRAIN_PCT=20 KERAS_TEST_PCT=5 KERAS_VALID_PCT=5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all takes a very long time to run.  We should not run this every time, rather just run it once to generate and save the VGG16 features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    vgg_model = VGG16(include_top=False, weights=\"imagenet\")\n",
    "vgg_model = parallelize_model_maybe(vgg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pull out all the images for feeding through VGG16 we use `class_mode=None` and `shuffled=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = count_images(\"train\")\n",
    "image_count_train_generator_cutoff = image_count_train / BATCH_SIZE + 1\n",
    "\n",
    "generator_train = make_generator(\n",
    "    \"train\",\n",
    "    data_gen_args={\"preprocessing_function\": preprocess_input},\n",
    "    data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                    \"class_mode\": None,\n",
    "                    \"shuffle\": False})\n",
    "generator_train_labels = make_generator(\n",
    "    \"train\",\n",
    "    data_gen_args={},\n",
    "    data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                    \"shuffle\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step takes a while.  I wish I could figure out a faster way to pull out just the labels in generator order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for i, (_, labels) in enumerate(generator_train_labels):\n",
    "    if i >= image_count_train_generator_cutoff:\n",
    "        break\n",
    "    else:\n",
    "        train_labels.extend(labels)\n",
    "train_labels = np.array(train_labels[:image_count_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this one takes super long, because we're running VGG16.  I've tried upping the batch size as much as I can, but it's still quite slow.  The resulting feature array is also quite huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = vgg_model.predict_generator(generator_train,\n",
    "                                         steps=image_count_train_generator_cutoff)\n",
    "train_data = train_data[:image_count_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_count_valid = count_images(\"valid\")\n",
    "image_count_valid_generator_cutoff = image_count_valid / BATCH_SIZE + 1\n",
    "\n",
    "generator_valid = make_generator(\n",
    "    \"valid\",\n",
    "    data_gen_args={\"preprocessing_function\": preprocess_input},\n",
    "    data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                    \"class_mode\": None,\n",
    "                    \"shuffle\": False})\n",
    "generator_valid_labels = make_generator(\n",
    "    \"valid\",\n",
    "    data_gen_args={},\n",
    "    data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                    \"shuffle\": False})\n",
    "\n",
    "valid_labels = []\n",
    "for i, (_, labels) in enumerate(generator_valid_labels):\n",
    "    if i >= image_count_valid_generator_cutoff:\n",
    "        break\n",
    "    else:\n",
    "        valid_labels.extend(labels)\n",
    "valid_labels = np.array(valid_labels[:image_count_valid])\n",
    "\n",
    "valid_data = vgg_model.predict_generator(generator_valid,\n",
    "                                         steps=image_count_valid_generator_cutoff)\n",
    "valid_data = valid_data[:image_count_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_test = count_images(\"test\")\n",
    "image_count_test_generator_cutoff = image_count_test / BATCH_SIZE + 1\n",
    "\n",
    "generator_test = make_generator(\n",
    "    \"test\",\n",
    "    data_gen_args={\"preprocessing_function\": preprocess_input},\n",
    "    data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                    \"class_mode\": None,\n",
    "                    \"shuffle\": False})\n",
    "generator_test_labels = make_generator(\n",
    "    \"test\",\n",
    "    data_gen_args={},\n",
    "    data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                    \"shuffle\": False})\n",
    "\n",
    "test_labels = []\n",
    "for i, (_, labels) in enumerate(generator_test_labels):\n",
    "    if i >= image_count_test_generator_cutoff:\n",
    "        break\n",
    "    else:\n",
    "        test_labels.extend(labels)\n",
    "test_labels = np.array(test_labels[:image_count_test])\n",
    "\n",
    "test_data = vgg_model.predict_generator(generator_test,\n",
    "                                        steps=image_count_test_generator_cutoff)\n",
    "test_data = test_data[:image_count_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Small Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_randomizer = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(train_randomizer)\n",
    "\n",
    "valid_randomizer = np.arange(valid_data.shape[0])\n",
    "np.random.shuffle(valid_randomizer)\n",
    "\n",
    "test_randomizer = np.arange(test_data.shape[0])\n",
    "np.random.shuffle(test_randomizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_r = train_data[train_randomizer]\n",
    "train_labels_r = train_labels[train_randomizer]\n",
    "\n",
    "valid_data_r = valid_data[valid_randomizer]\n",
    "valid_labels_r = valid_labels[valid_randomizer]\n",
    "\n",
    "test_data_r = test_data[test_randomizer]\n",
    "test_labels_r = test_labels[test_randomizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "def build_model(input_shape, target_num=NUM_CHARACTERS,\n",
    "               hidden_width=128, hidden_depth=1, dropout_rate=0.2):\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=input_shape))\n",
    "        for _ in range(hidden_depth):\n",
    "            model.add(Dense(hidden_width, activation='relu', \n",
    "                            kernel_initializer='lecun_uniform'))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(target_num, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def compile_model(model, learning_rate=LEARNING_RATE):\n",
    "    model = parallelize_model_maybe(model)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, start training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_model = build_model(train_data.shape[1:], hidden_width=512, hidden_depth=3, dropout_rate=0.2)\n",
    "tiny_model = compile_model(template_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_history = tiny_model.fit(train_data_r, train_labels_r,\n",
    "                                  epochs=15,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  validation_data=(valid_data_r, valid_labels_r),\n",
    "                                  callbacks=[stop_on_val_loss, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_model.save(os.path.join(DATA_DIR, datetime.datetime.today().strftime('%Y-%m-%d-%H-%M') + \"-tiny-model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can visualize our progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = valid_labels.argmax(1)\n",
    "pred_classes = tiny_model.predict(valid_data).argmax(1)\n",
    "class_names = [c for c, i in sorted(generator_valid.class_indices.items(), key=lambda pair: pair[1])]\n",
    "\n",
    "c_matrix = confusion_matrix(true_classes, pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(c_matrix, class_names, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Huge Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems I just can't get good results trying to save features and train a small network.  Maybe that bodes very poorly for my project.  But let's try training a giant network on the expensive amazon machines and just hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def init_model(target_num=NUM_CHARACTERS, learning_rate=LEARNING_RATE, \n",
    "               hidden_width=128, hidden_depth=1, dropout_rate=0.2):\n",
    "    input_shape = (IMAGE_ROW_SIZE, IMAGE_COLUMN_SIZE, 3)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        # Fine-tune prediction layer\n",
    "        pretrained_model = VGG16(include_top=False, weights='imagenet',\n",
    "                                 input_shape=input_shape)\n",
    "        for layer in pretrained_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        output_tensor = pretrained_model.output\n",
    "        output_tensor = Flatten()(output_tensor)\n",
    "        for _ in range(hidden_depth):\n",
    "            output_tensor = Dense(hidden_width, activation='relu', \n",
    "                                  kernel_initializer='lecun_uniform')(output_tensor)\n",
    "            output_tensor = Dropout(dropout_rate)(output_tensor)\n",
    "        output_tensor = Dense(target_num, activation=\"softmax\", \n",
    "                              name=\"predictions\")(output_tensor)\n",
    "\n",
    "        model = Model(inputs=pretrained_model.input, outputs=output_tensor)\n",
    "\n",
    "    model = parallelize_model_maybe(model)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=learning_rate),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model = init_model(hidden_width=256, hidden_depth=2, dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_history = big_model.fit_generator(generator=make_generator(\"train\"),\n",
    "                                           steps_per_epoch=steps_per_epoch(\"train\"),\n",
    "                                           epochs=5,\n",
    "                                           validation_data=make_generator(\"valid\"),\n",
    "                                           validation_steps=steps_per_epoch(\"valid\"),\n",
    "                                           callbacks=[stop_on_val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model.save(os.path.join(DATA_DIR, datetime.datetime.today().strftime('%Y-%m-%d-%H-%M') + \"-big-model.h5\"))"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}