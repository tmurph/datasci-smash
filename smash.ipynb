{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = [9, 8]\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 74)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DATADIR = \"data/keras\"\n",
    "NUM_CHARACTERS = len(os.listdir(os.path.join(DATADIR, \"train\", \"images\")))\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "IMAGE_ROW_SIZE = 584\n",
    "IMAGE_COLUMN_SIZE = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def make_generator(folder=\"train\",\n",
    "                   data_gen_args={\"fill_mode\": \"constant\",\n",
    "                                  \"cval\": 0,\n",
    "                                  \"width_shift_range\": 0.05,\n",
    "                                  \"height_shift_range\": 0.05,\n",
    "                                  \"zoom_range\": 0.1,\n",
    "                                  \"horizontal_flip\": True,\n",
    "                                  \"rescale\": 1.0 / 255,\n",
    "                                  \"preprocessing_function\": preprocess_input},\n",
    "                   data_flow_args={\"seed\": 1,\n",
    "                                   \"batch_size\": BATCH_SIZE}):\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        directory=os.path.join(DATADIR, folder, \"images\"),\n",
    "        target_size=(IMAGE_ROW_SIZE, IMAGE_COLUMN_SIZE),\n",
    "        color_mode='rgb',\n",
    "        **data_flow_args)\n",
    "\n",
    "    return image_generator\n",
    "\n",
    "\n",
    "def count_images(folder=\"train\"):\n",
    "    image_directory = os.path.join(DATADIR, folder, \"images\")\n",
    "    data_size = 0\n",
    "\n",
    "    for char_name in os.listdir(image_directory):\n",
    "        char_directory = os.path.join(image_directory, char_name)\n",
    "        data_size += len(os.listdir(char_directory))\n",
    "\n",
    "    return data_size\n",
    "\n",
    "\n",
    "def steps_per_epoch(folder=\"train\", batch_size=BATCH_SIZE):\n",
    "    return count_images(folder) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(include_top=False, weights=\"imagenet\")\n",
    "\n",
    "image_count_train = count_images(\"train\")\n",
    "generator_train = make_generator(\"train\",\n",
    "                                 data_gen_args={\"rescale\": 1.0 / 255},\n",
    "                                 data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                                                 \"class_mode\": None,\n",
    "                                                 \"shuffle\": False})\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(generator_train,\n",
    "                                                    image_count_train)\n",
    "np.save(open('bottleneck_features_train.npy', 'w'),\n",
    "        bottleneck_features_train)\n",
    "\n",
    "image_count_valid = count_images(\"valid\")\n",
    "generator_valid = make_generator(\"valid\",\n",
    "                                 data_gen_args={\"rescale\": 1.0 / 255},\n",
    "                                 data_flow_args={\"batch_size\": BATCH_SIZE,\n",
    "                                                 \"class_mode\": None,\n",
    "                                                 \"shuffle\": False})\n",
    "\n",
    "bottleneck_features_valid = model.predict_generator(generator_valid,\n",
    "                                                    image_count_valid)\n",
    "np.save(open('bottleneck_features_valid.npy', 'w'),\n",
    "        bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def init_model(target_num=4, dropout_ratio=0.5, learning_rate=0.0001):\n",
    "    input_shape = (IMAGE_ROW_SIZE, IMAGE_COLUMN_SIZE, 3)\n",
    "\n",
    "    # Fine-tune prediction layer\n",
    "    pretrained_model = VGG16(include_top=False, weights='imagenet',\n",
    "                             input_shape=input_shape)\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    output_tensor = pretrained_model.output\n",
    "    output_tensor = Flatten()(output_tensor)\n",
    "    output_tensor = Dense(128, activation='relu', \n",
    "                          kernel_initializer='lecun_uniform')(output_tensor)\n",
    "    # output_tensor = Dense(128, activation='relu', \n",
    "    #                       kernel_initializer='lecun_uniform')(output_tensor)\n",
    "    output_tensor = Dense(target_num, activation=\"softmax\", \n",
    "                          kernel_initializer='lecun_uniform', \n",
    "                          name=\"predictions\")(output_tensor)\n",
    "\n",
    "    # Define and compile the model\n",
    "    model = Model(inputs=pretrained_model.input, outputs=output_tensor)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model(target_num=NUM_CHARACTERS, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "stop_on_val_loss = EarlyStopping(monitor='val_loss', min_delta=0.005, \n",
    "                                 patience=2, verbose=0, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \n",
    "                              patience=2, min_lr=0.00001)\n",
    "\n",
    "training_history = model.fit_generator(generator=make_generator(\"train\"),\n",
    "                                       steps_per_epoch=steps_per_epoch(\"train\"),\n",
    "                                       epochs=20,\n",
    "                                       validation_data=make_generator(\"valid\"),\n",
    "                                       validation_steps=steps_per_epoch(\"valid\"),\n",
    "                                       callbacks=[stop_on_val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(DATADIR, datetime.datetime.today().strftime('%Y-%m-%d-%H-%M') + \"-FIXED-DATA.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_generator(folder=\"test\",\n",
    "                        data_flow_args={\"seed\": 1,\n",
    "                                        \"batch_size\": BATCH_SIZE}):\n",
    "\n",
    "    return ImageDataGenerator().flow_from_directory(\n",
    "        directory=os.path.join(DATADIR, folder, \"images\"),\n",
    "        target_size=(IMAGE_ROW_SIZE, IMAGE_COLUMN_SIZE),\n",
    "        color_mode='rgb',\n",
    "        **data_flow_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = make_test_generator()\n",
    "class_dict = test_batches.class_indices\n",
    "index_dict = {i: c for c, i in class_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, format(matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, vectors = next(test_batches)\n",
    "true_indices = vectors.argmax(1)\n",
    "predictions = model.predict_on_batch(images)\n",
    "prediction_indices = predictions.argmax(1)\n",
    "class_names = [c for i, c in sorted(index_dict.items())]\n",
    "\n",
    "cnf_matrix = confusion_matrix(true_indices, prediction_indices)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}